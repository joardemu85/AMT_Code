{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOorkkyzJbXj/ECRwGVOdXb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Written on 2024.05.22\n","\n","This notebook is used to perform 10-fold cross-validation to trained models based on EEGNET.\n","\n","The idea is to use the same training dataset used for the previously selected models. The workflow is as follows\n","\n","1. Load the training dataset\n","2. Generate a 10 fold iterator\n","3. Generate a model per fold\n","4. Save accuracies and accuracy plots.\n","\n","After exporting the models in .h5 format, these files will be used to predict with the testing subset and generate the confusion matrices per each fold (not sure if this is necessary, but I'll do it if I have time)"],"metadata":{"id":"cjM4T7tQWr-5"}},{"cell_type":"markdown","metadata":{"id":"SGf9VOgEN_fV"},"source":["# **1. Instancies and libraries**"]},{"cell_type":"markdown","metadata":{"id":"8YDVqpYDKlDo"},"source":["## 1.1 Add EEGNet library to the environmental variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZXtIJGgJj8X"},"outputs":[],"source":["import sys\n","path = \"/content/EEGNET\"\n","sys.path.append(path)"]},{"cell_type":"code","source":["!pip install pyyaml h5py"],"metadata":{"id":"d7G1FaLHL6E1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f44oLjpwIwuU"},"source":["## 1.2 Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIskn6nJXUiK"},"outputs":[],"source":["# Filesystem\n","import os\n","import zipfile\n","\n","# data processing\n","import numpy as np\n","import pandas as pd\n","\n","# AI-related\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import Callback\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","#library for cross validation\n","from sklearn.model_selection import StratifiedKFold\n","\n","# Plotting\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","#EEGNET\n","from EEGModels import EEGNet\n","from tensorflow.keras import utils as np_utils\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import backend as K\n"]},{"cell_type":"markdown","metadata":{"id":"rM-UzTbfjzCy"},"source":["# **2. Functions**"]},{"cell_type":"markdown","metadata":{"id":"0MkbqCZwNw4A"},"source":["## 2.1 Function to visualize the performance of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sD8OX4ZbdGFz"},"outputs":[],"source":["def visualize_results (model, n_epochs):\n","  epochs = [i for i in range (n_epochs)]\n","  fig, ax = plt.subplots(1,2)\n","  train_acc = model.history[\"accuracy\"]\n","  train_loss = model.history[\"loss\"]\n","  val_acc = model.history[\"val_accuracy\"]\n","  val_loss = model.history[\"val_loss\"]\n","  fig.set_size_inches(16,9)\n","\n","  ax[0].plot(epochs, train_acc, \"go-\", label = \"Training Accuracy\")\n","  ax[0].plot(epochs, val_acc, \"ro-\", label = \"Validation Accuracy\")\n","  ax[0].set_title(\"Training and Validation Accuracy\")\n","  ax[0].legend()\n","  ax[0].set_xlabel(\"Epochs\")\n","  ax[0].set_ylabel(\"Accuracy\")\n","\n","  ax[1].plot(epochs, train_loss, \"go-\", label = \"Training Loss\")\n","  ax[1].plot(epochs, val_loss, \"ro-\", label = \"Validation Loss\")\n","  ax[1].set_title(\"Training and Validation Loss\")\n","  ax[1].legend()\n","  ax[1].set_xlabel(\"Epochs\")\n","  ax[1].set_ylabel(\"Loss\")\n","\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"bio4y2lON8WA"},"source":["## 2.2 **Function** to plot Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZ5F84MEAl-j"},"outputs":[],"source":["def plot_confusion_matrix (cm,\n","                           classes,\n","                           normalize = False,\n","                           title = 'Confusion Matrix',\n","                           cmap=plt.cm.Greens\n","                          ):\n","  plt.imshow (cm, interpolation='nearest', cmap=cmap)\n","  plt.title (title)\n","  plt.colorbar()\n","  tick_marks = np.arange(len(classes))\n","  plt.xticks(tick_marks, classes, rotation=45)\n","  plt.yticks(tick_marks, classes)\n","\n","  if normalize:\n","    cm=cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n","    print(\"Normalized confusion matrix\")\n","  else:\n","    print(\"Confusion matrix, without normalization\")\n","  print(cm)\n","\n","  thresh = cm.max()*0.80\n","  for i, j in itertools.product (range(cm.shape[0]), range(cm.shape[1])):\n","     plt.text(j, i, round(cm[i,j],2),\n","              horizontalalignment=\"center\",\n","              color=\"white\" if cm [i, j] > thresh else \"black\")\n","\n","  plt.tight_layout()\n","  plt.ylabel('True Label')\n","  plt.xlabel('Predicted Label')"]},{"cell_type":"markdown","metadata":{"id":"mH0BeEq5PGGG"},"source":["## 2.3 Function to normalize EEG data (run inside the loop to assemble the tensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GEW1rJ2YZPaH"},"outputs":[],"source":["def normalize_channels (data, n_channels):\n","  data_norm = np.zeros_like(data, dtype='float32')\n","  for ch in range (n_channels):\n","      min_val = (np.min(data[ch]))\n","      max_val = (np.max(data[ch]))\n","      data_norm [ch] = (data[ch] - min_val) / (max_val - min_val)\n","\n","  return data_norm"]},{"cell_type":"markdown","metadata":{"id":"9w782Xw3llmp"},"source":["# **3. Data Load**"]},{"cell_type":"markdown","metadata":{"id":"en_-72ntl40p"},"source":["## 3.1 Unzip dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCwm5FJFsnrc"},"outputs":[],"source":["local_zip = \"/content/ERP_Pretest_Data_128Hz.zip\"\n","zip_ref = zipfile.ZipFile(local_zip, \"r\")\n","zip_ref.extractall(\"/content/ERP_Pretest_Data_128_Hz\")\n","zip_ref.close()"]},{"cell_type":"markdown","metadata":{"id":"Zp6AMQBzmE7_"},"source":["## 3.2 Define file paths"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PW8miKzNft8"},"outputs":[],"source":["train_data_path = \"/content/ERP_Pretest_Data_128_Hz/Train/\""]},{"cell_type":"markdown","metadata":{"id":"kjnq9azEmhy5"},"source":["## 3.3 Load file lists"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2fcwKxwRmg3M"},"outputs":[],"source":["trainlist = open  (\"/content/ERP_Pretest_Data_128_Hz/TrainFileList.txt\", \"r\")\n","data = trainlist.read()\n","train_data_all_files = data.split(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"V7AHe_dBnFdi"},"source":["## 3.4 Determine the number of trials available based on the number of files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ntECh0BnF-P"},"outputs":[],"source":["n_trials_train = len(train_data_all_files)"]},{"cell_type":"markdown","metadata":{"id":"u0CPP8zBncMz"},"source":["## 3.5 Define the parameters for EEG data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eGfe4ryBni5Y"},"outputs":[],"source":["n_channels = 20\n","n_samples = 128\n","n_kernels = 1\n","\n","ch_names = ['Fz', 'F7', 'F3', 'F4', 'F8',\n","            'T7', 'C3', 'CZ', 'C4', 'T8',\n","            'P7', 'P3', 'Pz', 'P4', 'P8',\n","            'O1', 'Oz', 'O2', 'LM', 'RM']\n","\n","sfreq = 128\n","#info = mne.create_info(ch_names = ch_names, sfreq = sfreq)"]},{"cell_type":"markdown","metadata":{"id":"xMOQ6dhEn2xE"},"source":["## 3.6 Load training data\n","\n","This data will be loaded as 2D array for augmentation and balancing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UnFZsXuAoJqk"},"outputs":[],"source":["train_set_2D = np.zeros ((n_trials_train,n_channels*n_samples), dtype='float32')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q21Z2NaQoPUP"},"outputs":[],"source":["trial = 0\n","for filename in train_data_all_files:\n","  data = pd.read_csv(filename, header=None, dtype=np.float32)\n","  trl = np.reshape (np.array(data), (n_channels*n_samples))\n","  train_set_2D[trial:] = trl\n","  trial=trial+1"]},{"cell_type":"markdown","metadata":{"id":"Bn0zyUjAoSyz"},"source":["Load labels for training data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJNpbYT4yStr"},"outputs":[],"source":["train_labels_path = '/content/ERP_Pretest_Data_128_Hz/TrainLabels.csv'\n","y_0 = np.array(pd.read_csv(train_labels_path, header=None, dtype='uint8'))\n","y_0 = np.squeeze(y_0.T)"]},{"cell_type":"markdown","metadata":{"id":"QvMhBIOOoe1e"},"source":["Balance the training set using the Random Oversampler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzM6zh1molgo"},"outputs":[],"source":["oversampler_train = RandomOverSampler(sampling_strategy='minority')\n","traindata_over, trainlabels_over = oversampler_train.fit_resample(train_set_2D, y_0)\n","(overTrials_tr, overSamples_tr) = traindata_over.shape"]},{"cell_type":"markdown","metadata":{"id":"79kzgLkmo881"},"source":["Allocate data in tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G53bYJkgo8AI"},"outputs":[],"source":["X = np.zeros((overTrials_tr,n_channels,n_samples), dtype=np.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VqkNLOAkpHD-","outputId":"5de938b8-8b98-4596-df9a-7f7acd280d8a","executionInfo":{"status":"ok","timestamp":1716422967857,"user_tz":-540,"elapsed":1024,"user":{"displayName":"Jorge DELGADO-MUNOZ","userId":"16950807984901489288"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(1342,)\n"]}],"source":["for i in range(overTrials_tr):\n","  trl_rs = np.reshape (traindata_over[i],(n_channels,n_samples))\n","  # Optional operation to check if this improves the model performance\n","  trl_rs = normalize_channels(np.array(trl_rs, dtype='float32'), n_channels)\n","  X[i] = trl_rs\n","\n","# reasign the training labels\n","y = trainlabels_over\n","print(y.shape)"]},{"cell_type":"markdown","source":["# 4 EEGNET Section"],"metadata":{"id":"dpY5hJVipCW4"}},{"cell_type":"markdown","source":["# 4.1 Define parameters for architecture"],"metadata":{"id":"kvkGXrGFpIgX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6917LZiTCx2"},"outputs":[],"source":["# Model Build\n","classes = 2\n","dropout_rate = 0.2                  # hp.Float  ('dropoutRate',  min_value=0.2, max_value=0.5, sampling=\"log\")\n","kernel_length = 64                  # hp.Choice ('kernLength', values = [16, 32, 64])\n","f1 = 8                              # hp.Choice ('F1', values = [4, 8])\n","d = 2                               # hp.Choice ('D', values = [1, 2])\n","f2 = f1*d\n","dropout_type = 'SpatialDropout2D'   # hp.Choice ('dropoutType', values = ['Dropout', 'SpatialDropout'])\n","\n","# Compile\n","lr = 1e-4                           # hp.Float  ('learning_rate',  min_value=1e-6, max_value=1e-2, sampling=\"log\")\n","\n","                                    # hp.Int ('epochs', min_value = 50, max_value = 500, step = 50)\n","\n","batch = 64\n","epoch = 300"]},{"cell_type":"markdown","metadata":{"id":"Xb9Ez4wQnAPj"},"source":["# 4.2 Generate model architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MDWjgyqRnACU","outputId":"f8472588-e0b3-4dd0-9fc7-43a5d891a4cc","collapsed":true,"executionInfo":{"status":"ok","timestamp":1716423028482,"user_tz":-540,"elapsed":1417,"user":{"displayName":"Jorge DELGADO-MUNOZ","userId":"16950807984901489288"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 20, 128, 1)]      0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 20, 128, 8)        512       \n","                                                                 \n"," batch_normalization (Batch  (None, 20, 128, 8)        32        \n"," Normalization)                                                  \n","                                                                 \n"," depthwise_conv2d (Depthwis  (None, 1, 128, 16)        320       \n"," eConv2D)                                                        \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 1, 128, 16)        64        \n"," chNormalization)                                                \n","                                                                 \n"," activation (Activation)     (None, 1, 128, 16)        0         \n","                                                                 \n"," average_pooling2d (Average  (None, 1, 32, 16)         0         \n"," Pooling2D)                                                      \n","                                                                 \n"," spatial_dropout2d (Spatial  (None, 1, 32, 16)         0         \n"," Dropout2D)                                                      \n","                                                                 \n"," separable_conv2d (Separabl  (None, 1, 32, 16)         512       \n"," eConv2D)                                                        \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 1, 32, 16)         64        \n"," chNormalization)                                                \n","                                                                 \n"," activation_1 (Activation)   (None, 1, 32, 16)         0         \n","                                                                 \n"," average_pooling2d_1 (Avera  (None, 1, 4, 16)          0         \n"," gePooling2D)                                                    \n","                                                                 \n"," spatial_dropout2d_1 (Spati  (None, 1, 4, 16)          0         \n"," alDropout2D)                                                    \n","                                                                 \n"," flatten (Flatten)           (None, 64)                0         \n","                                                                 \n"," dense (Dense)               (None, 2)                 130       \n","                                                                 \n"," sigmoid (Activation)        (None, 2)                 0         \n","                                                                 \n","=================================================================\n","Total params: 1634 (6.38 KB)\n","Trainable params: 1554 (6.07 KB)\n","Non-trainable params: 80 (320.00 Byte)\n","_________________________________________________________________\n"]}],"source":["EEGNET_Model = EEGNet(nb_classes = classes,\n","                       Chans = n_channels,\n","                       Samples = n_samples,\n","                       dropoutRate = dropout_rate,\n","                       kernLength = kernel_length,\n","                       F1 = f1,\n","                       D = d,\n","                       F2 = f2,\n","                       dropoutType = dropout_type)\n","\n","EEGNET_Model.summary()"]},{"cell_type":"markdown","source":["# 5. Cross-validation settings"],"metadata":{"id":"KiK_6Y3LrB-x"}},{"cell_type":"code","source":["import keras\n","from keras import optimizers\n","\n","# Define number of folds\n","n_splits = 10\n","\n","# Initialize StratifiedKFold\n","skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n","\n","# Lists to store evaluation results\n","accuracies = []\n","\n","# Perform n-fold cross-validation\n","# for train_index, val_index in skf.split(X, y):\n","for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n","\n","    X_train, X_val = X[train_index], X[val_index]\n","    y_train, y_val = y[train_index], y[val_index]\n","\n","    # reshape to one-hot encodings\n","    # datasets\n","    X_train = X_train.reshape(X_train.shape[0], n_channels, n_samples, n_kernels)\n","    X_val  = X_val.reshape(X_val.shape[0], n_channels, n_samples, n_kernels)\n","\n","    #labels\n","    y_train = np_utils.to_categorical(y_train)\n","    y_val = np_utils.to_categorical(y_val)\n","\n","\n","    opt = keras.optimizers.Adam(learning_rate = lr)\n","\n","    #Checkpointer\n","    checkpoint_filename = '/tmp/'+'checkpoint' + str (fold) + '.h5'\n","    checkpointer = ModelCheckpoint(filepath=checkpoint_filename,\n","                                   verbose=1,\n","                                   save_best_only=True)\n","\n","    EEGNET_Model.compile(loss='binary_crossentropy',\n","                         optimizer=opt,\n","                         metrics = ['accuracy'])\n","\n","    #load weights from externalfile\n","    EEGNET_Model.load_weights('/content/Weights/EEGNEt_Model8.h5')\n","\n","\n","    fittedModel = EEGNET_Model.fit(X_train,\n","                                   y_train,\n","                                   batch_size = batch,\n","                                   epochs = epoch,\n","                                   verbose = 2,\n","                                   validation_data=(X_val, y_val),\n","                                   callbacks=[checkpointer])\n","\n","    # load optimal weights\n","    EEGNET_Model.load_weights(checkpoint_filename)\n","\n","    # Evaluate the model on the validation set\n","    _, accuracy = EEGNET_Model.evaluate(X_val, y_val)\n","    accuracies.append(accuracy)\n","\n","    #plot output\n","    print ('Fold ' + str (fold))\n","    visualize_results (fittedModel, epoch)\n","\n","    # Save model output\n","    model_filepath = '/content/Models/EEGNET_model_fold_' + str(fold) + '.h5'\n","    EEGNET_Model.save(model_filepath)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1k-WKuAiE75v6J-h5l3GzMNxCtgQr4ARX"},"id":"gFHDsv_XrSDw","executionInfo":{"status":"ok","timestamp":1716425228216,"user_tz":-540,"elapsed":702540,"user":{"displayName":"Jorge DELGADO-MUNOZ","userId":"16950807984901489288"}},"outputId":"40644fee-ad07-4941-d186-3f69d5cb39b5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["print(\"Average accuracy:\", np.mean(accuracies))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RYFxyKrkwxnd","executionInfo":{"status":"ok","timestamp":1716425246427,"user_tz":-540,"elapsed":470,"user":{"displayName":"Jorge DELGADO-MUNOZ","userId":"16950807984901489288"}},"outputId":"511f7775-411d-45cb-f97a-154c5ad829a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average accuracy: 0.813736867904663\n"]}]},{"cell_type":"code","source":["outputfile = '/content/Models/EEGNET_Accuracies.csv'\n","df = pd.DataFrame({'Accuracy': accuracies})\n","df.to_csv(outputfile)"],"metadata":{"id":"ZLfsTMWQHYGK"},"execution_count":null,"outputs":[]}]}